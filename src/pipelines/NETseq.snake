# ===== Snake file for processing mNET-seq data ================================


# Python packages
from pytools.persistent_dict import PersistentDict
import os
import glob
import re
import subprocess
import gzip
import random


# Configure shell for all rules
shell.executable("/bin/bash")
shell.prefix("source ~/.bash_profile; set -o nounset -o pipefail -o errexit -x; ")


# Docker container
container:
    config["CONTAINER"]


# Parameters from config.yaml
PROJ        = config["PROJ"]
RAW_DATA    = config["RAW_DATA"]
RESULTS     = config["RESULTS"]
ALL_SAMPLES = config["SAMPLES"]
INDEX       = config["INDEX"]
CHROMS      = config["CHROMS"]
GTF         = config["GTF"]
GENES       = config["GENES"]
MASK        = config["MASK"]
MEMORY      = config["MEMORY"]
URL         = config["URL"]
SSH         = config["SSH"]
CMD_PARAMS  = config["CMD_PARAMS"]
TEST_GENES  = config["TEST_GENES"]

META_BEDS = config["META_BEDS"]
GENE_SUB_BEDS = config["GENE_SUBSAMPLE_BEDS"]


# Directories for data and scripts
FASTQ_DIR = RESULTS + "/fastqs"
REF       = "ref"
SRC       = "src"


# Files for metaplots
GENE_SUB_REGS = list(GENE_SUB_BEDS.keys())

if GENE_SUB_REGS & META_BEDS.keys():
    sys.exit("ERROR: META_BEDS and GENE_SUBSAMPLE_BEDS must have different labels. Files provided by GENE_SUBSAMPLE_BEDS will get added to META_BEDS.")

META_BEDS.update(dict(GENE_SUB_BEDS))

REGIONS = list(META_BEDS.keys())


# Scripts to compile
SCRIPTS = glob.glob(os.path.join(SRC, "*.cpp"))
SCRIPTS = [os.path.splitext(os.path.basename(script))[0] for script in SCRIPTS]


# Simplify ALL_SAMPLES dictionary
# subsampling groups can be listed in multiple sections
# collapse sections and combine subsampling groups
SAMPLES = {}

for _, d in ALL_SAMPLES.items():
    for key, value in d.items():

        if not isinstance(value, dict):
            value = {key: value}  # make it a dictionary for uniformity

        for _, sub_value in value.items():
            if key in SAMPLES:
                if sub_value not in SAMPLES[key]:
                    SAMPLES[key].append(sub_value)

            else:
                SAMPLES[key] = [sub_value]


# Sample and group lists
SAMS = [[y, x] for y in SAMPLES for x in SAMPLES[y]]
GRPS = [x[0] for x in SAMS]
SAMS = [x[1] for x in SAMS]

def _get_uniq_list(list_in):
    seen = set()
    out = []
    
    for item in list_in:
        if item not in seen:
            seen.add(item)
            out.append(item)

    return(out)

GRPS_UNIQ = _get_uniq_list(GRPS)
SAMS_UNIQ = _get_uniq_list(SAMS)


# Gene subsampling groups
SAM_GRPS      = [x + "-" + y for y in SAMPLES for x in SAMPLES[y]]
GENE_SUB_GRPS = [x + "_" + y for x in SAM_GRPS for y in GENE_SUB_REGS]
GENE_SUB_GRPS = SAM_GRPS + GENE_SUB_GRPS


# Print summary of samples and groups
print("SAMS (%s): %s\n" % (len(SAMS), SAMS))
print("GRPS (%s): %s\n" % (len(GRPS), GRPS))
print("SAMS_UNIQ (%s): %s\n" % (len(SAMS_UNIQ), SAMS_UNIQ))
print("GRPS_UNIQ (%s): %s\n" % (len(GRPS_UNIQ), GRPS_UNIQ))
print("SAM_GRPS (%s): %s\n" % (len(SAM_GRPS), SAM_GRPS))

print("GENE_SUB_BEDS (%s): %s\n" % (len(GENE_SUB_BEDS), GENE_SUB_BEDS))

print("GENE_SUB_GRPS (%s): %s\n" % (len(GENE_SUB_GRPS), GENE_SUB_GRPS))


# Wildcard constraints
GRP_REGEX = "[a-zA-Z0-9\-]+"

wildcard_constraints:
    region  = "[a-zA-Z0-9\-]+",
    reads   = "[a-zA-Z]+",
    length  = "[a-zA-Z]+",
    sample  = "[a-zA-Z0-9_]+",
    group   = GRP_REGEX,
    sam_grp = "[a-zA-Z0-9_\-]+-[a-zA-Z0-9_\-]+"


# Create symlinks for fastqs
if not os.path.exists(FASTQ_DIR):
    os.makedirs(FASTQ_DIR)

def _get_sfx(sfx):
    if sfx == ".fastq.gz":
        fq_sfx = ["_" + x + "_001" + sfx for x in ["R1", "R2"]]

    elif sfx == ".fq.gz":
        fq_sfx = ["_" + x + sfx for x in ["1", "2"]]

    else:
        fq_sfx = sfx

    return fq_sfx

def _get_fqs(sample, dirs, full_name = False):
    fq_pat   = ".*" + sample + r".+\.(fastq|fq)\.gz$"
    fq_paths = []
    
    for dir in dirs:
        all_files = glob.glob(os.path.abspath(os.path.join(dir, "*.gz")))
        paths     = [f for f in all_files if re.match(fq_pat, f)]
    
        for path in paths:
            fq_paths.append(path)

    if not fq_paths:
        sys.exit("ERROR: no fastqs found for " + fq_pat + ".")

    # Identify fastq suffix
    sfx = []
    
    for fq in fq_paths:
        if re.search(r"\.fastq\.gz$", fq):
            sf = ".fastq.gz"
    
        if re.search(r"\.fq\.gz$", fq):
            sf = ".fq.gz"
    
        sfx.append(sf)
    
    sfx = set(sfx)
    
    if len(sfx) > 1:
        sys.exit("ERROR: Multiple fastqs found for " + sample + ".")
    
    sfx  = list(sfx)[0]
    sfxs = _get_sfx(sfx)

    # Find matching fastqs and create symlinks 
    fastqs = []
    
    for full_sfx in sfxs:
        fq_pat = ".*/" + sample + ".*" + full_sfx
    
        fq = [f for f in fq_paths if re.match(fq_pat, f)]
    
        # Check for duplicate paths
        if not fq:
            sys.exit("ERROR: no fastqs found for " + fq_pat + ".")
    
        if len(fq) > 1:
            sys.exit("ERROR: Multiple fastqs found for " + fq_pat + ".")
    
        fq = fq[0]
    
        fastq = os.path.basename(fq)

        # Create symlinks
        # Using subprocess since os.symlink requires a target file instead of
        # target directory
        fq_lnk = FASTQ_DIR + "/" + fastq
    
        if not os.path.exists(fq_lnk):
            cmd = "ln -s " + fq + " " + FASTQ_DIR
    
            if cmd != "":
                subprocess.run(cmd, shell = True)
    
        # Return fastq path or just the fastq name
        if full_name:
            fastqs.append(fq_lnk)
    
        else:
            fastqs.append(re.sub(sfx + "$", "", fastq))
    
    return(fastqs)

FASTQS = [_get_fqs(x, RAW_DATA) for x in SAMS_UNIQ]


# Final output files
rule all:
    input:
        # Compile scripts
        expand(
            SRC + "/{script}",
            script = SCRIPTS
        ),

        # FastQC
        RESULTS + "/stats/" + PROJ + "_fastqc.tsv",

        # Cutadapt
        RESULTS + "/stats/" + PROJ + "_cutadapt.tsv",

        # Bowtie2
        RESULTS + "/stats/" + PROJ + "_bowtie.tsv",
        
        # De-duplication
        RESULTS + "/stats/" + PROJ + "_dedup.tsv",
        
        # FeatureCounts
        RESULTS + "/" + PROJ + "_featureCounts.tsv",

        # Filtering summary
        RESULTS + "/stats/" + PROJ + "_filt.tsv",

        # Sample subsampling
        expand(
            RESULTS + "/{sample}-{group}/{sample}-{group}.bed.gz",
            zip, sample = SAMS, group = GRPS
        ),

        RESULTS + "/stats/" + PROJ + "_subsample.tsv",
        
        # Gene subsampling
        expand(
            RESULTS + "/stats/{group}_{sub_region}_summary.tsv",
            group = GRPS_UNIQ, sub_region = GENE_SUB_REGS
        ),

        # Bigwigs without subsampling
        RESULTS + "/urls/" + PROJ + "_nosub_igv.xml",

        # Bigwigs with subsampling
        expand(
            RESULTS + "/{sam_grp}/{sam_grp}_neg.bw",
            sam_grp = GENE_SUB_GRPS
        ),

        RESULTS + "/urls/" + PROJ + "_igv.xml",

        # Metaplots without subsampling
        expand(
            RESULTS + "/{sample}/metaplot_beds/{sample}_{region}_S_N.bed.gz",
            sample = SAMS, region = REGIONS
        ),

        # Metaplots with subsampling
        expand(
            RESULTS + "/{sam_grp}/metaplot_beds/{sam_grp}_{region}_S_N.bed.gz",
            sam_grp = GENE_SUB_GRPS, region = REGIONS
        ),

        # Gene subsampling test
        expand(
            RESULTS + "/stats/{group}_{sub_region}_test.tsv",
            group = GRPS_UNIQ, sub_region = GENE_SUB_REGS
        ),

        # Library subsampling test
        expand(
            RESULTS + "/stats/{group}_test.tsv",
            group = GRPS_UNIQ
        )


# Compile C++ code
include: "../rules/00_setup.snake"

# Run FastQC
include: "../rules/01_fastqc.snake"

# Run cutadapt
include: "../rules/01_cutadapt.snake"

# Align reads with bowtie2
include: "../rules/02_bowtie.snake"

# Remove PCR duplicates with UMI-tools
include: "../rules/03_dedup.snake"

# Run featureCounts
include: "../rules/04_featureCounts.snake"

# Files without subsampling
include: "../rules/04_metaplots_nosub.snake"
include: "../rules/05_bigwigs_nosub.snake"

# Sample subsampling
include: "../rules/04_subsample.snake"

# Gene subsampling
include: "../rules/05_gene_subsample.snake"

# Create bigwigs
include: "../rules/06_bigwigs.snake"

# Create bed files for metaplots
include: "../rules/06_metaplots_stranded.snake"

# Test output files
include: "../rules/07_test.snake"


