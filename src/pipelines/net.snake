# ===== Snake file for processing mNET-seq data ================================


# Configure shell for all rules
shell.executable("/bin/bash")
shell.prefix("source ~/.bash_profile; set -o nounset -o pipefail -o errexit -x; ")


# Python packages
import os
import shutil
import glob
import re


# Add genome specific config
GENOME = config["GENOME"]

GENOME_CONFIG = "src/configs/" + GENOME + ".yaml"

if not os.path.exists(GENOME_CONFIG):
    sys.exit("ERROR: " + GENOME + " is not a valid GENOME selection.")

configfile:
    GENOME_CONFIG


# Include intermediate files
do_nothing = lambda x: x

if config["KEEP_INTERMEDIATE_FILES"]:
    temp_fn = do_nothing
else:
    temp_fn = temp

if config["KEEP_META_FILES"]:
    meta_temp_fn = do_nothing
else:
    meta_temp_fn = temp


# # Docker container
# singularity:
#     config["CONTAINER"]


# Parameters from config.yaml
PROJ           = config["PROJ"]
RAW_DATA       = config["RAW_DATA"]
RESULTS        = config["RESULTS"]
ALL_SAMPLES    = config["SAMPLES"]
INDEX          = config["INDEX"]
CHROMS         = config["CHROMS"]
GTF            = config["GTF"]
GENES          = config["GENES"]
MASK           = config["MASK"]
MEMORY         = config["MEMORY"]
URL            = config["URL"]
SSH            = config["SSH"]
SSH_KEY_DIR    = config["SSH_KEY_DIR"]
CMD_PARAMS     = config["CMD_PARAMS"]
READ_1_ADAPTER = config["READ_1_ADAPTER"]
READ_2_ADAPTER = config["READ_2_ADAPTER"]
TEST_GENES     = config["TEST_GENES"]

GENE_SUB_BEDS      = config["GENE_SUBSAMPLE_BEDS"]
META_BEDS          = config["META_BEDS"]
META_MATRIX_BED    = config["META_MATRIX_BED"]
META_MATRIX_PARAMS = config["META_MATRIX_PARAMS"]


# Functions for pipeline
include: "../rules.py"
include: "../funs.py"


# Function to return memory specification for rule
# define this in the Snakefile since the function needs access
# to the MEMORY variable
# n:        multiplier to use when base_mem is provided
# mult:     conversion multiplier to convert final memory calculation to
#           different unit, default returns GB
# base_mem: base memory in GB, if this is not provided, memory is
#           calculated based on input file size
# min_mem:  minimum memory in GB
def _get_mem(n = 1, mult = 1, base_mem = MEMORY, min_mem = 1):

    if base_mem:
        import math
    
        mem = math.ceil(base_mem * n)
        mem = max(mem, min_mem)
        mem = mem * mult

    else:
        mem = lambda wildcards, input: max(3 * input.size_mb / 1000, min_mem) * mult

    return mem


# Directories for data and scripts
FASTQ_DIR    = RESULTS + "/fastqs"
DICT_DIR     = RESULTS + "/dicts"
SUB_DICT_DIR = DICT_DIR + "/SUB_DICT"
SRC          = "src"

os.makedirs(FASTQ_DIR, exist_ok = True)
os.makedirs(DICT_DIR, exist_ok = True)


# Files for metaplots
# * Need to transpose matrix params list
GENE_SUB_REGS = list(GENE_SUB_BEDS.keys())

if GENE_SUB_REGS & META_BEDS.keys():
    sys.exit("ERROR: META_BEDS and GENE_SUBSAMPLE_BEDS must have different labels. Files provided by GENE_SUBSAMPLE_BEDS will get added to META_BEDS.")

META_BEDS.update(dict(GENE_SUB_BEDS))

REGIONS = list(META_BEDS.keys())

META_MATRIX_PARAMS = list(map(list, zip(*META_MATRIX_PARAMS)))


# Scripts to compile
SCRIPTS = glob.glob(SRC + "/*.cpp")
SCRIPTS = [os.path.splitext(os.path.basename(script))[0] for script in SCRIPTS]


# Simplify ALL_SAMPLES dictionary
# subsampling groups can be listed in multiple sections
# collapse sections and combine subsampling groups
SAMPLES = {}

for _, d in ALL_SAMPLES.items():
    for key, value in d.items():

        if not isinstance(value, dict):
            value = {key: value}  # make it a dictionary for uniformity

        for _, sub_value in value.items():
            if key in SAMPLES:
                if sub_value not in SAMPLES[key]:
                    SAMPLES[key].append(sub_value)

            else:
                SAMPLES[key] = [sub_value]


# Sample and group lists
# do not use list(set()) since need to maintain order
SAMS = [[y, x] for y in SAMPLES for x in SAMPLES[y]]
GRPS = [x[0] for x in SAMS]
SAMS = [x[1] for x in SAMS]

GRPS_UNIQ = _get_uniq_list(GRPS)
SAMS_UNIQ = _get_uniq_list(SAMS)


# Gene subsampling groups
SAM_GRPS      = [x + "-" + y for y in SAMPLES for x in SAMPLES[y]]
GENE_SUB_GRPS = [x + "_" + y for x in SAM_GRPS for y in GENE_SUB_REGS]
GENE_SUB_GRPS = SAM_GRPS + GENE_SUB_GRPS


# Dicts to set adapter sequences for each sample
def _create_adapter_dict(adapter):
    
    if not isinstance(adapter, dict):
        if not isinstance(adapter, str):
            sys.exit("ERROR: READ_*_ADAPTER must be a single value or a dictionary")

        adapter = {key: adapter for key in SAMS_UNIQ}

    if not all(item in adapter for item in SAMS_UNIQ):
        sys.exit("ERROR: READ_*_ADAPTER must include a sequence for each sample")

    return(adapter)

READ_1_ADAPTER = _create_adapter_dict(READ_1_ADAPTER)
READ_2_ADAPTER = _create_adapter_dict(READ_2_ADAPTER)


# Print summary of samples and groups
print("\nSAMS (%s): %s\n" % (len(SAMS), SAMS))
print("GRPS (%s): %s\n" % (len(GRPS), GRPS))
print("SAMS_UNIQ (%s): %s\n" % (len(SAMS_UNIQ), SAMS_UNIQ))
print("GRPS_UNIQ (%s): %s\n" % (len(GRPS_UNIQ), GRPS_UNIQ))
print("SAM_GRPS (%s): %s\n" % (len(SAM_GRPS), SAM_GRPS))

print("GENE_SUB_BEDS (%s): %s\n" % (len(GENE_SUB_BEDS), GENE_SUB_BEDS))

print("GENE_SUB_GRPS (%s): %s\n" % (len(GENE_SUB_GRPS), GENE_SUB_GRPS))


# Wildcard constraints
GRP_REGEX = "[a-zA-Z0-9-]+"

wildcard_constraints:
    region  = "[a-zA-Z0-9-]+",
    reads   = "[a-zA-Z]+",
    length  = "[a-zA-Z]+",
    sample  = "[a-zA-Z0-9_]+",
    group   = GRP_REGEX,
    sam_grp = "[a-zA-Z0-9_-]+-[a-zA-Z0-9_-]+",

    win          = "[0-9]+",
    stren        = "(_(?!sep).*_)",
    stren_grp    = "(_(?!sep).*_|_)",
    pause_region = "[a-zA-Z0-9-]+"


# Create symlinks for fastqs
FASTQS = [_get_fqs(x, RAW_DATA, FASTQ_DIR) for x in SAMS_UNIQ]
FASTQS = sum(FASTQS, [])


# Pausing pipeline
include: "pauses.snake"


# Final output files
rule all:
    input:
        # Compile scripts
        expand(
            SRC + "/{script}",
            script = SCRIPTS
        ),

        # FastQC
        RESULTS + "/stats/" + PROJ + "_fastqc.tsv",

        # Cutadapt
        RESULTS + "/stats/" + PROJ + "_cutadapt.tsv",

        # Bowtie2
        RESULTS + "/stats/" + PROJ + "_bowtie.tsv",
        
        # De-duplication
        RESULTS + "/stats/" + PROJ + "_dedup.tsv",
        
        # FeatureCounts
        RESULTS + "/" + PROJ + "_featureCounts.tsv",

        # Filtering summary
        RESULTS + "/stats/" + PROJ + "_filt.tsv",

        # Sample subsampling
        RESULTS + "/stats/" + PROJ + "_subsample.tsv",
        
        # Gene subsampling
        expand(
            RESULTS + "/stats/{group}_{sub_region}_summary.tsv",
            group = GRPS_UNIQ, sub_region = GENE_SUB_REGS
        ),

        expand(
            DICT_DIR + "/{group}_{sub_region}_cleanup.txt",
            group = GRPS_UNIQ, sub_region = GENE_SUB_REGS
        ),

        # Bigwigs without subsampling
        RESULTS + "/urls/" + PROJ + "_nosub_igv.xml",
        RESULTS + "/urls/" + PROJ + "_nosub_urls.tsv",

        RESULTS + "/urls/" + PROJ + "_nofilt_igv.xml",
        RESULTS + "/urls/" + PROJ + "_nofilt_urls.tsv",

        # Bigwigs with subsampling
        expand(
            RESULTS + "/{sam_grp}/{sam_grp}_neg.bw",
            sam_grp = GENE_SUB_GRPS
        ),

        RESULTS + "/urls/" + PROJ + "_igv.xml",
        RESULTS + "/urls/" + PROJ + "_urls.tsv",

        # Metaplot matrices
        RESULTS + "/urls/" + PROJ + "_matrix_urls.tsv",

        # Subsampling tests
        RESULTS + "/stats/" + PROJ + "_subsample_test.tsv",

        RESULTS + "/stats/" + PROJ + "_gene_subsample_test.tsv",

        # Pauses
        expand(
            RESULTS + "/{sam_grp}/pauses/{sam_grp}_{win}_pauses.bed.gz",
            sam_grp = GENE_SUB_GRPS, win = WIN_SIZE
        ),

        expand(
            RESULTS + "/stats/" + PROJ + "_{win}{stren_grp}pausing.tsv",
            sam_grp = GENE_SUB_GRPS, win = WIN_SIZE, stren_grp = ALL_STREN_GRPS
        ),

        # Plots
        RESULTS + "/" + PROJ + "_analysis.html"


# Setup code for pipeline
include: "../rules/00_setup.snake"

# Run FastQC
include: "../rules/01_fastqc.snake"

# Run cutadapt
include: "../rules/01_cutadapt.snake"

# Align reads with bowtie2
include: "../rules/02_bowtie.snake"

# Remove PCR duplicates with UMI-tools
include: "../rules/03_dedup.snake"

# Run featureCounts
include: "../rules/04_featureCounts.snake"

# Create bigwigs
include: "../rules/06_bigwigs.snake"
include: "../rules/04_bigwigs_nosub.snake"

# Create matrices for metaplots
include: "../rules/05_metaplot_matrices.snake"

# Create bed files for metaplots
include: "../rules/06_metaplots.snake"
include: "../rules/04_metaplots_nosub.snake"

# Sample subsampling
include: "../rules/04_subsample.snake"

# Gene subsampling
include: "../rules/05_gene_subsample.snake"

# Test output files
include: "../rules/07_test.snake"

# Generate plots
include: "../rules/08_plots.snake"


