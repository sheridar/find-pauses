# ====== Rules for removing PCR duplicates with UMI-tools ======================


# Remove duplicate reads
rule dedup:
    input:
        bam = RESULTS + "/{sample}/{sample}.bam",
        bai = RESULTS + "/{sample}/{sample}.bam.bai"
    output:
        bam   = temp_fn(RESULTS + "/{sample}/{sample}_dedup.bam"),
        bai   = temp_fn(RESULTS + "/{sample}/{sample}_dedup.bam.bai"),
        stats = RESULTS + "/{sample}/{sample}_dedup_stats.txt"
    params:
        job_name = "{sample}_dedup",
        memory   = MEMORY * 3,
        args     = CMD_PARAMS["umi_tools"],
        log      = RESULTS + "/logs/{sample}_dedup.out"
    log:
        out = RESULTS + "/logs/{sample}_dedup.out",
        err = RESULTS + "/logs/{sample}_dedup.err"
    message:
        "Removing duplicates for {wildcards.sample}"
    threads:
        1
    shell:
        """
        umi_tools dedup \
            {params.args} \
            -I {input.bam} \
            -S {output.bam} \
            -L {output.stats}

        samtools index {output.bam}
        """


# Create duplication summary
rule dedup_summary:
    input:
        expand(
            RESULTS + "/{sample}/{sample}_dedup_stats.txt",
            sample = SAMS_UNIQ
        )
    output:
        RESULTS + "/stats/" + PROJ + "_dedup.tsv"
    params:
        job_name = PROJ + "_dedup_summary",
        memory   = 4
    log:
        out = RESULTS + "/logs/" + PROJ + "_dedup_summary.out",
        err = RESULTS + "/logs/" + PROJ + "_dedup_summary.err"
    message:
        "Creating " + PROJ + " dedup summary"
    threads:
        1
    run:
        with open(output[0], "w") as out:
            metrics = [
                "Input Reads: [0-9]+",
                "Number of reads out: [0-9]+",
                "Total number of positions deduplicated: [0-9]+",
                "Mean number of unique UMIs per position: [0-9\.]+",
                "Max. number of unique UMIs per position: [0-9]+"
            ]

            for file in input:
                name  = os.path.basename(file)
                name  = re.sub("_dedup_stats.txt", "", name)

                for line in open(file, "r"):
                    for metric in metrics:
                        met = re.search(metric, line)

                        if met:
                            met = met.group(0)
                            num = re.search("[0-9\.]+$", met).group(0)
                            met = re.sub(": [0-9\.]+$", "", met)

                            out.write("%s\t%s\t%s\n" % (name, met, num))


# Create bed files for RNA 3' end
rule create_beds:
    input:
        RESULTS + "/{sample}/{sample}_dedup.bam",
        expand(SRC + "/{script}", script = SCRIPTS)
    output:
        bed   = temp_fn(RESULTS + "/{sample}/{sample}.bed.gz"),
        shift = RESULTS + "/{sample}/{sample}_shift.bed.gz",
        stats = temp(RESULTS + "/{sample}/{sample}_filt_stats.tsv")
    params:
        job_name = "{sample}_create_beds",
        memory   = MEMORY * 3,
        genes    = GENES,
        mask     = MASK
    log:
        out = RESULTS + "/logs/{sample}_beds.out",
        err = RESULTS + "/logs/{sample}_beds.err"
    benchmark:
        RESULTS + "/benchmarks/{sample}_beds.tsv"
    message:
        "Creating bed files for {wildcards.sample}"
    threads:
        12
    shell:
       """
       # Create bed file for aligned reads
       bamToBed -i {input[0]} \
           | awk -v OFS="\t" -v sam="{wildcards.sample}" '{{
               if ($1 !~ "^chr") {{
                   $1 = "chr"$1
               }};
               count += 1;
               print $0, $3 - $2
           }} END {{
               print sam, "Aligned reads", count \
                   > "{output.stats}"
           }}' \
           | sort -S1G --parallel={threads} -k1,1 -k2,2n \
           | pigz -p {threads} \
           > {output.bed}

       # Filter for reads that are within params.gene and not within
       # params.mask. This filtering is not strand specific. Collapse
       # read coordinates to the RNA 3' end.
       zcat {output.bed} \
           | bedtools intersect -sorted -v  -a - -b {params.mask} \
           | bedtools intersect -sorted -wa -a - -b {params.genes} \
           | sort -S1G --parallel={threads} -k1,1 -k2,2n -k4,4 -u \
           | awk -v OFS="\t" -v sam="{wildcards.sample}" '{{
               if ($6 == "+") {{
                   $2 = $3 - 1;
               }} else {{
                   $3 = $2 + 1;
               }};
               count += 1;
               print
           }} END {{
               print sam, "Filtered reads", count \
                   >> "{output.stats}";
           }}' \
           | sort -S1G --parallel={threads} -k1,1 -k2,2n \
           | pigz -p {threads} \
           > {output.shift}
       """

        
# Create filtering summary
rule filt_summary:
    input:
        expand(
            RESULTS + "/{sample}/{sample}_filt_stats.tsv",
            sample = SAMS_UNIQ
        )
    output:
        RESULTS + "/stats/"+ PROJ + "_filt.tsv"
    params:
        job_name = PROJ + "_filt_summary",
        memory   = 4
    log:
        out = RESULTS + "/logs/" + PROJ + "_filt_summary.out",
        err = RESULTS + "/logs/" + PROJ + "_filt_summary.err"
    message:
        "Creating " + PROJ + " read filtering summary"
    threads:
        1
    shell:
        """
        file_arr=({input})

        for file in ${{file_arr[@]}}
        do
            cat $file \
                >> {output}
        done
        """


