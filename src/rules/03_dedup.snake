# ====== Rules for removing PCR duplicates with UMI-tools ======================


# Remove duplicate reads
rule dedup:
    input:
        bam = RESULTS + "/{sample}/{sample}.bam",
        bai = RESULTS + "/{sample}/{sample}.bam.bai"
    output:
        bam   = temp_fn(RESULTS + "/{sample}/{sample}_dedup.bam"),
        bai   = temp_fn(RESULTS + "/{sample}/{sample}_dedup.bam.bai"),
        stats = RESULTS + "/{sample}/{sample}_dedup_stats.txt"
    params:
        job_name = "{sample}_dedup",
        args     = CMD_PARAMS["umi_tools"]
    resources:
        mem_mb = _get_mem(3, 1000),
        mem_gb = _get_mem(3)
    log:
        out = RESULTS + "/logs/{sample}_dedup.out",
        err = RESULTS + "/logs/{sample}_dedup.err"
    threads:
        1
    shell:
        """
        umi_tools dedup \
            {params.args} \
            -I '{input.bam}' \
            -S '{output.bam}' \
            -L '{output.stats}'

        samtools index '{output.bam}'
        """


# Create duplication summary
rule dedup_summary:
    input:
        expand(
            RESULTS + "/{sample}/{sample}_dedup_stats.txt",
            sample = SAMS_UNIQ
        )
    output:
        RESULTS + "/stats/" + PROJ + "_dedup.tsv"
    params:
        job_name = PROJ + "_dedup_summary"
    resources:
        mem_mb = _get_mem(0.125, 1000),
        mem_gb = _get_mem(0.125)
    log:
        out = RESULTS + "/logs/" + PROJ + "_dedup_summary.out",
        err = RESULTS + "/logs/" + PROJ + "_dedup_summary.err"
    threads:
        1
    shell:
        """
        python - << 'EOF'
import sys
sys.path.insert(0, "{SRC}")

import rules

rules._dedup_summary("{input}".split(), "{output[0]}")
EOF
        """


# Create bed files for RNA 3' end
rule beds:
    input:
        RESULTS + "/{sample}/{sample}_dedup.bam",
        expand(SRC + "/{script}", script = SCRIPTS)
    output:
        bed    = temp_fn(RESULTS + "/{sample}/{sample}.bed.gz"),
        shift  = RESULTS + "/{sample}/{sample}_shift.bed.gz",
        nofilt = RESULTS + "/{sample}/{sample}_nofilt.bed.gz",
        stats  = temp(RESULTS + "/{sample}/{sample}_filt_stats.tsv")
    params:
        job_name = "{sample}_create_beds",
        genes    = GENES,
        mask     = MASK
    resources:
        mem_mb = _get_mem(3, 1000),
        mem_gb = _get_mem(3)
    log:
        out = RESULTS + "/logs/{sample}_beds.out",
        err = RESULTS + "/logs/{sample}_beds.err"
    benchmark:
        RESULTS + "/benchmarks/{sample}_beds.tsv"
    threads:
        12
    shell:
       """
       # Create bed file for aligned reads
       bamToBed -i {input[0]} \
           | awk -v OFS="\t" -v sam='{wildcards.sample}' '{{
               if ($1 !~ "^chr") {{
                   $1 = "chr"$1
               }};
               count += 1;
               print $0, $3 - $2
           }} END {{
               print sam, "Aligned reads", count \
                   > "{output.stats}"
           }}' \
           | sort -S1G --parallel={threads} -k1,1 -k2,2n \
           | bedtools intersect -sorted -v  -a - -b {params.mask} \
           | pigz -p {threads} \
           > '{output.bed}'

       # Filter for reads that are within params.gene and not within
       # params.mask. This filtering is not strand specific. Collapse
       # read coordinates to the RNA 3' end.
       zcat '{output.bed}' \
           | bedtools intersect -sorted -wa -a - -b {params.genes} \
           | awk -v OFS="\t" -v sam='{wildcards.sample}' '{{
               if ($6 == "+") {{
                   $2 = $3 - 1;
               }} else {{
                   $3 = $2 + 1;
               }};
               count += 1;
               print
           }} END {{
               print sam, "Filtered reads", count \
                   >> "{output.stats}";
           }}' \
           | sort -S1G --parallel={threads} -k1,1 -k2,2n \
           | pigz -p {threads} \
           > '{output.shift}'

       zcat '{output.bed}' \
           | awk -v OFS="\t" '{{
               if ($6 == "+") {{
                   $2 = $3 - 1;
               }} else {{
                   $3 = $2 + 1;
               }};
               print
           }}' \
           | sort -S1G --parallel={threads} -k1,1 -k2,2n \
           | pigz -p {threads} \
           > '{output.nofilt}'
       """

        
# Create filtering summary
rule filt_summary:
    input:
        expand(
            RESULTS + "/{sample}/{sample}_filt_stats.tsv",
            sample = SAMS_UNIQ
        )
    output:
        RESULTS + "/stats/"+ PROJ + "_filt.tsv"
    params:
        job_name = PROJ + "_filt_summary"
    resources: 
        mem_mb = _get_mem(0.125, 1000),
        mem_gb = _get_mem(0.125)
    log:
        out = RESULTS + "/logs/" + PROJ + "_filt_summary.out",
        err = RESULTS + "/logs/" + PROJ + "_filt_summary.err"
    threads:
        1
    shell:
        """
        file_arr=({input})

        for file in ${{file_arr[@]}}
        do
            cat "$file" \
                >> '{output}'
        done
        """


