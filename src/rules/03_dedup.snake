# ====== Rules for removing PCR duplicates with UMI-tools ======================


# Create bed files for RNA 3' end
rule create_beds:
    input:
        RESULTS + "/{sample}/{sample}.bam",
        expand(SRC + "/{script}", script = SCRIPTS)
    output:
        bed   = temp_fn(RESULTS + "/{sample}/{sample}.bed.gz"),
        shift = RESULTS + "/{sample}/{sample}_shift.bed.gz",
        stats = temp(RESULTS + "/{sample}/{sample}_filt_stats.tsv")
    params:
        job_name = "{sample}_create_beds",
        genes    = GENES,
        mask     = MASK
    resources:
        mem_gb = _get_mem(3)
    log:
        out = RESULTS + "/logs/{sample}_beds.out",
        err = RESULTS + "/logs/{sample}_beds.err"
    benchmark:
        RESULTS + "/benchmarks/{sample}_beds.tsv"
    threads:
        12
    shell:
       """
       # Create bed file for aligned reads
       bamToBed -i {input[0]} \
           | awk -v OFS="\t" -v sam='{wildcards.sample}' '{{
               if ($1 !~ "^chr") {{
                   $1 = "chr"$1
               }};
               count += 1;
               print $0, $3 - $2
           }} END {{
               print sam, "Aligned reads", count \
                   > "{output.stats}"
           }}' \
           | sort -S1G --parallel={threads} -k1,1 -k2,2n \
           | pigz -p {threads} \
           > '{output.bed}'

       # Filter for reads that are within params.gene and not within
       # params.mask. This filtering is not strand specific. Collapse
       # read coordinates to the RNA 3' end.
       zcat '{output.bed}' \
           | bedtools intersect -sorted -v  -a - -b {params.mask} \
           | bedtools intersect -sorted -wa -a - -b {params.genes} \
           | sort -S1G --parallel={threads} -k1,1 -k2,2n -k4,4 -u \
           | awk -v OFS="\t" -v sam='{wildcards.sample}' '{{
               if ($6 == "+") {{
                   $3 = $2 + 1;
               }} else {{
                   $2 = $3 - 1;
               }};
               count += 1;
               print
           }} END {{
               print sam, "Filtered reads", count \
                   >> "{output.stats}";
           }}' \
           | sort -S1G --parallel={threads} -k1,1 -k2,2n \
           | pigz -p {threads} \
           > '{output.shift}'
       """

        
# Create filtering summary
rule filt_summary:
    input:
        expand(
            RESULTS + "/{sample}/{sample}_filt_stats.tsv",
            sample = SAMS_UNIQ
        )
    output:
        RESULTS + "/stats/"+ PROJ + "_filt.tsv"
    params:
        job_name = PROJ + "_filt_summary"
    resources:
        mem_gb = _get_mem(0.125)
    log:
        out = RESULTS + "/logs/" + PROJ + "_filt_summary.out",
        err = RESULTS + "/logs/" + PROJ + "_filt_summary.err"
    threads:
        1
    shell:
        """
        file_arr=({input})

        for file in ${{file_arr[@]}}
        do
            cat "$file" \
                >> '{output}'
        done
        """


