# ===== Rules for intersecting reads with genomic regions ======================


# Identify lowest counts for the gene among all samples in the sampling group
# for input, need to pull all files for the sampling group, but need each job
# to only include files for one sampling region
# snakemake does not support the use of singularity with the 'run' directive
# as a work around call python using the 'shell' directive
rule gene_subsample_1:
    input:
        lambda wildcards: expand(
            RESULTS + "/{sample}/metaplot_beds/{sample}_{{sub_region}}_S.bed.gz",
            sample = SAMPLES[wildcards.group]
        )
    output:
        RESULTS + "/stats/{group}_{sub_region}_summary.tsv"
    params:
        job_name = "{group}_{sub_region}_summary"
    resources:
        mem_gb = _get_mem(2)
    log:
        out = RESULTS + "/logs/{group}_{sub_region}_summary.out",
        err = RESULTS + "/logs/{group}_{sub_region}_summary.err"
    benchmark:
        RESULTS + "/benchmarks/{group}_{sub_region}_genes_summary.tsv"
    threads:
        1
    shell:
        """
        python - << 'EOF'
import sys
sys.path.insert(0, "{SRC}/rules")

import rules

rules._gene_subsample_1(
    "{input}".split(),
    "{output[0]}",
    "{wildcards.group}",
    "{wildcards.sub_region}",
    "{DICT_DIR}"
)
EOF
        """


# Subsample reads so each gene for each sample has the same total counts for
# the subsampling region
rule gene_subsample_2:
    input:
        reads = RESULTS  + "/{sample}/{sample}_shift.bed.gz",
        bed   = RESULTS  + "/{sample}/metaplot_beds/{sample}_{sub_region}_S.bed.gz",
        sum   = RESULTS  + "/stats/{group}_{sub_region}_summary.tsv"
    output:
        reads =      RESULTS + "/{sample}-{group}_{sub_region}/{sample}-{group}_{sub_region}_reads.bed.gz",
        tmp   = temp(RESULTS + "/{sample}-{group}_{sub_region}/{sample}-{group}_{sub_region}_tmp.bed"),
        sub   =      RESULTS + "/{sample}-{group}_{sub_region}/{sample}-{group}_{sub_region}.bed.gz"
    params:
        job_name = "{sample}_{group}_{sub_region}"
    resources:
        mem_gb = _get_mem(2)
    log:
        out = RESULTS + "/logs/{sample}_{group}_{sub_region}.out",
        err = RESULTS + "/logs/{sample}_{group}_{sub_region}.err"
    benchmark:
        RESULTS + "/benchmarks/{sample}_{group}_{sub_region}.tsv"
    threads:
        6
    shell:
        """
        # Intersect with subsampling region
        # this produces a bed file that only containing reads to use for
        # subsampling
        zcat '{input.reads}' \
            | bedtools intersect -sorted -s -a '{input.bed}' -b - \
            | sort -S1G --parallel={threads} -k1,1 -k4,4 -k2,2n \
            | pigz -p {threads} \
            > '{output.reads}'

        python - << 'EOF'
import sys
sys.path.insert(0, "{SRC}/rules")

import rules

rules._gene_subsample_2(
    "{output.reads}",
    "{output.tmp}",
    "{wildcards.group}",
    "{wildcards.sub_region}",
    "{DICT_DIR}"
)
EOF

        # Sort and zip bed file
        cat '{output.tmp}' \
            | sort -S1G --parallel={threads} -k1,1 -k2,2n \
            | pigz -p {threads} \
            > '{output.sub}'
        """


# Clear dictionaries used for gene subsampling
rule gene_subsample_cleanup:
    input:
        lambda wildcards: expand(
            RESULTS + "/{sample}-{{group}}_{{sub_region}}/{sample}-{{group}}_{{sub_region}}.bed.gz",
            sample = SAMPLES[wildcards.group]
        )
    output:
        temp(touch(DICT_DIR + "/{group}_{sub_region}_cleanup.txt"))
    params:
        job_name = "{group}_{sub_region}_cleanup"
    resources:
        mem_gb = _get_mem(0.125)
    log:
        out = RESULTS + "/logs/{group}_{sub_region}_cleanup.out",
        err = RESULTS + "/logs/{group}_{sub_region}_cleanup.err"
    threads:
        1
    shell:
        """
        python - << 'EOF'
import sys
sys.path.insert(0, "{SRC}/rules")

import funs

GENE_SUB_DICT = funs._get_gene_sub_dict(
    "{wildcards.group}",
    "{wildcards.sub_region}",
    "{DICT_DIR}"
)

GENE_SUB_DICT.clear()

EOF
        """


